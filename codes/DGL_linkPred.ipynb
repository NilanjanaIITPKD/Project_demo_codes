{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DGL_linkPred.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4U4iGHqQt5f"
      },
      "outputs": [],
      "source": [
        "!pip install dgl-cu113 dglgo -f https://data.dgl.ai/wheels/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy.sparse as sp"
      ],
      "metadata": {
        "id": "KPM8nGh0R4Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl.data\n",
        "dataset = dgl.data.CoraGraphDataset()\n",
        "g = dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shfQ3sYiRTZO",
        "outputId": "0874df93-1153-4f92-d21d-f12c9b9badb5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split edge set for training and testing\n",
        "u, v = g.edges()\n",
        "\n",
        "eids = np.arange(g.number_of_edges())\n",
        "eids = np.random.permutation(eids)\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.number_of_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "# Find all negative edges and split them for training and testing\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "\n",
        "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
        "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
        "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]"
      ],
      "metadata": {
        "id": "ud7VxRERSFIU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_g = dgl.remove_edges(g, eids[:test_size])"
      ],
      "metadata": {
        "id": "gSUxjV9BabbQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import SAGEConv\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "H8vmPT6iS6NU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())"
      ],
      "metadata": {
        "id": "AnZsF47jZZei"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl.function as fn\n",
        "\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            # Compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata['score'][:, 0]"
      ],
      "metadata": {
        "id": "qRQL5nzBZcbI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, h_feats):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
        "        self.W2 = nn.Linear(h_feats, 1)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        \"\"\"\n",
        "        Computes a scalar score for each edge of the given graph.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        edges :\n",
        "            Has three members ``src``, ``dst`` and ``data``, each of\n",
        "            which is a dictionary representing the features of the\n",
        "            source nodes, the destination nodes, and the edges\n",
        "            themselves.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            A dictionary of new edge features.\n",
        "        \"\"\"\n",
        "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
        "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            g.apply_edges(self.apply_edges)\n",
        "            return g.edata['score']"
      ],
      "metadata": {
        "id": "-UhOMvjkZekz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
        "# You can replace DotPredictor with MLPPredictor.\n",
        "#pred = MLPPredictor(16)\n",
        "pred = DotPredictor()\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    return roc_auc_score(labels, scores)"
      ],
      "metadata": {
        "id": "J9af4d7bZf4u"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "# in this case, loss will in training loop\n",
        "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    # forward\n",
        "    h = model(train_g, train_g.ndata['feat'])\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print('In epoch {}, loss: {}'.format(e, loss))\n",
        "\n",
        "# ----------- 5. check results ------------------------ #\n",
        "from sklearn.metrics import roc_auc_score\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "    print('AUC', compute_auc(pos_score, neg_score))\n",
        "\n",
        "\n",
        "# Thumbnail credits: Link Prediction with Neo4j, Mark Needham\n",
        "# sphinx_gallery_thumbnail_path = '_static/blitz_4_link_predict.png'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76rFlL5DZjNY",
        "outputId": "20df0df5-1489-455f-a7e8-4f2826986407"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 0.6929987072944641\n",
            "In epoch 5, loss: 0.6608156561851501\n",
            "In epoch 10, loss: 0.5720950961112976\n",
            "In epoch 15, loss: 0.5138760805130005\n",
            "In epoch 20, loss: 0.4815983474254608\n",
            "In epoch 25, loss: 0.45374736189842224\n",
            "In epoch 30, loss: 0.433806836605072\n",
            "In epoch 35, loss: 0.40967419743537903\n",
            "In epoch 40, loss: 0.38904714584350586\n",
            "In epoch 45, loss: 0.3670644164085388\n",
            "In epoch 50, loss: 0.3466932475566864\n",
            "In epoch 55, loss: 0.3260969817638397\n",
            "In epoch 60, loss: 0.3052796423435211\n",
            "In epoch 65, loss: 0.2853683829307556\n",
            "In epoch 70, loss: 0.26476916670799255\n",
            "In epoch 75, loss: 0.2449629306793213\n",
            "In epoch 80, loss: 0.22497312724590302\n",
            "In epoch 85, loss: 0.2051982879638672\n",
            "In epoch 90, loss: 0.18573495745658875\n",
            "In epoch 95, loss: 0.1665499359369278\n",
            "AUC 0.8550167336762426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jEd8yYHSalU_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}