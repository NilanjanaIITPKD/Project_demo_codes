{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DGL_GCN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl\n",
        "!pip install torch==1.9.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJzqCNCsF_lL",
        "outputId": "420ccfb0-0667-4d53-ea0f-cab5f648192f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.6.1\n",
            "Collecting torch==1.9.1\n",
            "  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 6.3 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1) (4.2.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k8rx9gBCF3W4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5657e4-f8b3-4906-fe8c-d6530fed32f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: pytorch\n"
          ]
        }
      ],
      "source": [
        "import dgl\n",
        "import dgl.function as fn\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl import DGLGraph\n",
        "\n",
        "#define the message and reduce function . u denotes source node .\n",
        "gcn_msg = fn.copy_u(u='h', out='m')  # copy_u() specifies unary message function . input feature name = u = 'h' , output message name = out = 'm'\n",
        "gcn_reduce = fn.sum(msg='m', out='h') #the aggregation on a node u only involves summing over the neighbors’ representations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.linear = nn.Linear(in_feats, out_feats)\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        # Creating a local scope so that all the stored ndata and edata\n",
        "        # (such as the `'h'` ndata below) are automatically popped out\n",
        "        # when the scope exits.\n",
        "        # By entering a local scope, any out-place mutation to the feature \n",
        "        # data will not reflect to the original graph, thus making it easier to \n",
        "        # use in a function scope (e.g. forward computation of a model).\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = feature    # set nodedata\n",
        "            g.update_all(gcn_msg, gcn_reduce)   # update the graph using message function and reduce function \n",
        "            h = g.ndata['h']      \n",
        "            return self.linear(h)       # pass h through linear layer"
      ],
      "metadata": {
        "id": "_OfQSyfhF7Ac"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.layer1 = GCNLayer(1433, 16) #gcn layer 1\n",
        "        self.layer2 = GCNLayer(16, 7) #gcn layer 2\n",
        "\n",
        "    # forward pass\n",
        "    def forward(self, g, features):\n",
        "        x = F.relu(self.layer1(g, features))      #relu activation in hidden layer \n",
        "        x = self.layer2(g, x)\n",
        "        return x\n",
        "net = Net()\n",
        "print(net)    # print the network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaRZceVyGR0C",
        "outputId": "0d0b9936-5b6a-4fb1-f707-27c6979e889f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (layer1): GCNLayer(\n",
            "    (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
            "  )\n",
            "  (layer2): GCNLayer(\n",
            "    (linear): Linear(in_features=16, out_features=7, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.data import CoraGraphDataset    \n",
        "\n",
        "# load cora dataset \n",
        "def load_cora_data():\n",
        "    dataset = CoraGraphDataset()\n",
        "    g = dataset[0]  \n",
        "    print(g)                # only one graph is present in cora dataset \n",
        "    features = g.ndata['feat']      # graph node features \n",
        "    labels = g.ndata['label']       # node labels \n",
        "    train_mask = g.ndata['train_mask']    #\n",
        "    test_mask = g.ndata['test_mask']\n",
        "    print( test_mask)\n",
        "    return g, features, labels, train_mask, test_mask\n",
        "\n",
        "load_cora_data()"
      ],
      "metadata": {
        "id": "P63WaioJGVcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a24dddc-f730-4fd2-a73f-9074a90e18e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "Graph(num_nodes=2708, num_edges=10556,\n",
            "      ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool)}\n",
            "      edata_schemes={})\n",
            "tensor([False, False, False,  ...,  True,  True,  True])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Graph(num_nodes=2708, num_edges=10556,\n",
              "       ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool)}\n",
              "       edata_schemes={}), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([3, 4, 4,  ..., 3, 3, 3]), tensor([ True,  True,  True,  ..., False, False, False]), tensor([False, False, False,  ...,  True,  True,  True]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, g, features, labels, mask):\n",
        "    model.eval()                            # model evaluation \n",
        "    with th.no_grad():                      # disabling gradient calculation as it is not required in  test phase\n",
        "        logits = model(g, features)         # get logits\n",
        "        logits = logits[mask]               # apply mask\n",
        "        labels = labels[mask]\n",
        "        _, indices = th.max(logits, dim=1)\n",
        "        correct = th.sum(indices == labels)\n",
        "        return correct.item() * 1.0 / len(labels)   # get percentage of accuracy \n",
        "\n",
        "\n",
        "# evaluate(net, g, features, labels, test_mask)"
      ],
      "metadata": {
        "id": "Wsz8uJGGGb1O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "g, features, labels, train_mask, test_mask = load_cora_data()\n",
        "# Add edges between each node and itself to preserve old node representations\n",
        "g.add_edges(g.nodes(), g.nodes())\n",
        "optimizer = th.optim.Adam(net.parameters(), lr=1e-2)        # adam optimiser\n",
        "dur = []\n",
        "for epoch in range(50):\n",
        "    if epoch >=3:\n",
        "        t0 = time.time()\n",
        "\n",
        "    net.train()                                             # train network\n",
        "    logits = net(g, features)\n",
        "    logp = F.log_softmax(logits, 1)\n",
        "    loss = F.nll_loss(logp[train_mask], labels[train_mask]) # calculate loss using negetive log likelihood\n",
        "\n",
        "    optimizer.zero_grad()                                   # Sets the gradients of all optimized tensors to zero.\n",
        "    loss.backward()                                         # back propagation \n",
        "    optimizer.step()                                        #\n",
        "\n",
        "    if epoch >=3:\n",
        "        dur.append(time.time() - t0)\n",
        "\n",
        "    acc = evaluate(net, g, features, labels, test_mask)      # calculate accuracy\n",
        "    print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(epoch, loss.item(), acc, np.mean(dur)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fodSB3M2Gfgn",
        "outputId": "0ec63689-f7c2-4c77-fb69-66f4b505821d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "Graph(num_nodes=2708, num_edges=10556,\n",
            "      ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool)}\n",
            "      edata_schemes={})\n",
            "tensor([False, False, False,  ...,  True,  True,  True])\n",
            "logits tensor([[ 0.0804, -0.1010, -0.1894,  ...,  0.2333, -0.1182, -0.1701],\n",
            "        [ 0.1302, -0.0741, -0.2311,  ...,  0.2990, -0.1073, -0.1473],\n",
            "        [-0.1045, -0.2556,  0.1757,  ...,  0.7600, -1.0007, -0.4314],\n",
            "        ...,\n",
            "        [ 0.1418, -0.0594, -0.2369,  ...,  0.1466,  0.0591, -0.1324],\n",
            "        [ 0.0648, -0.1275, -0.1705,  ...,  0.2288, -0.1830, -0.2041],\n",
            "        [-0.0351, -0.2037,  0.0332,  ...,  0.3469, -0.5150, -0.3370]])\n",
            "mask tensor([False, False, False,  ...,  True,  True,  True])\n",
            "logits tensor([[-0.5163, -0.5777,  1.7527,  ...,  0.8970, -2.3515, -0.5739],\n",
            "        [-0.8885, -0.9075,  2.4119,  ...,  1.3757, -3.1879, -0.8171],\n",
            "        [-0.6602, -0.7296,  2.0239,  ...,  1.0037, -2.5374, -0.6637],\n",
            "        ...,\n",
            "        [ 0.1418, -0.0594, -0.2369,  ...,  0.1466,  0.0591, -0.1324],\n",
            "        [ 0.0648, -0.1275, -0.1705,  ...,  0.2288, -0.1830, -0.2041],\n",
            "        [-0.0351, -0.2037,  0.0332,  ...,  0.3469, -0.5150, -0.3370]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7fkZpnywGi1f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}